{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stimuli for training and test for MB3-Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>syllable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./FinalStimuliCopy/ke.wav</td>\n",
       "      <td>ke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./FinalStimuliCopy/fu.wav</td>\n",
       "      <td>fu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./FinalStimuliCopy/fa.wav</td>\n",
       "      <td>fa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fname syllable\n",
       "0  ./FinalStimuliCopy/ke.wav       ke\n",
       "1  ./FinalStimuliCopy/fu.wav       fu\n",
       "2  ./FinalStimuliCopy/fa.wav       fa"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavfiles = pd.DataFrame({'fname':glob.glob('./FinalStimuliCopy/*.wav')}) # Get list of files\n",
    "#wavfiles = pd.DataFrame({'fname':wavfiles['fname'].apply(lambda x: x[-6:])}) # Extract .wav filenames\n",
    "syllables=wavfiles['fname'].apply(lambda x: x[-6:-4]) # Extract list of syllables\n",
    "wavfiles['syllable']=syllables # STore list of syllables in df\n",
    "wavfiles.head(3) # Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training stimuli\n",
    "#### NB: first COLUMN is all the A syllables, and the remaining columns are the B syllables, placed in rows such that the  first column (A) syllables can be combined with all other syllables of that row (B syllables) (except the xx in last row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ku', 'me', 'fa', 'pe'],\n",
       "       ['ke', 'fa', 'fu', 'pu'],\n",
       "       ['mu', 'ka', 'fa', 'pe'],\n",
       "       ['ma', 'fu', 'pe', 'pu'],\n",
       "       ['fe', 'ka', 'pe', 'pu'],\n",
       "       ['pa', 'me', 'fu', 'xx']], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingset = np.array(['ku', 'me', 'fa', 'pe'], dtype=object)\n",
    "trainingset = np.vstack([trainingset,['ke',  'fa', 'fu', 'pu']])\n",
    "trainingset = np.vstack([trainingset,['mu',  'ka', 'fa', 'pe']])\n",
    "trainingset = np.vstack([trainingset,['ma',  'fu', 'pe', 'pu']])\n",
    "trainingset = np.vstack([trainingset,['fe',  'ka', 'pe', 'pu']])\n",
    "trainingset = np.vstack([trainingset,['pa',  'me', 'fu', 'xx']])\n",
    "trainingset # Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test stimuli\n",
    "#### Each row has an allowed combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ti', 'so'],\n",
       "       ['si', 'to'],\n",
       "       ['no', 'li'],\n",
       "       ['lo', 'ni']], dtype='<U2')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = np.array([['ti', 'so'],['si', 'to'],['no', 'li'],['lo', 'ni']])\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training sentences for ABB and ABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the 250ms silence file\n",
    "wavSIL250 = AudioSegment.from_wav('./SILfiles/SIL250ms.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for syllA in np.arange(0,trainingset.shape[0]): # The first syllable of each row..\n",
    "    dumA = trainingset[syllA,0] # A syllable name\n",
    "    for syllB in np.arange(1,trainingset.shape[1]):\n",
    "        dumB = trainingset[syllA,syllB] # B syllable name\n",
    "        if not(dumB=='xx'): # the last entry..\n",
    "            # Get names of wave files in dummy variables\n",
    "            dumAfname = wavfiles.loc[wavfiles['syllable']==dumA,'fname'].to_list()[0] \n",
    "            dumBfname = wavfiles.loc[wavfiles['syllable']==dumB,'fname'].to_list()[0]\n",
    "            # Read in wave info from A and B syllable files\n",
    "            wavA = AudioSegment.from_wav(dumAfname)\n",
    "            wavB = AudioSegment.from_wav(dumBfname)\n",
    "            \n",
    "            # Combine all wavs into one including 250ms silences: ABB\n",
    "            outwav = wavA + wavSIL250 + wavB + wavSIL250 + wavB\n",
    "            # Write to file\n",
    "            sentencename = './TrainingSentences/ABB/'+dumA+dumB+dumB+'.wav'\n",
    "            outwav.export(sentencename, format=\"wav\")\n",
    "\n",
    "            # Combine all wavs into one including 250ms silences: ABA\n",
    "            outwav = wavA + wavSIL250 + wavB + wavSIL250 + wavA\n",
    "            # Write to file\n",
    "            sentencename = './TrainingSentences/ABA/'+dumA+dumB+dumA+'.wav'\n",
    "            outwav.export(sentencename, format=\"wav\")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, create test sentences for ABB and ABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the 250ms silence file\n",
    "wavSIL250 = AudioSegment.from_wav('./SILfiles/SIL250ms.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for syllA in np.arange(0,testset.shape[0]): # The first syllable of each row..\n",
    "    dumA = testset[syllA,0] # A syllable name\n",
    "    dumB = testset[syllA,1] # A syllable name\n",
    "    \n",
    "    # Get names of wave files in dummy variables\n",
    "    dumAfname = wavfiles.loc[wavfiles['syllable']==dumA,'fname'].to_list()[0] \n",
    "    dumBfname = wavfiles.loc[wavfiles['syllable']==dumB,'fname'].to_list()[0]\n",
    "    # Read in wave info from A and B syllable files\n",
    "    wavA = AudioSegment.from_wav(dumAfname)\n",
    "    wavB = AudioSegment.from_wav(dumBfname)\n",
    "\n",
    "    # Combine all wavs into one including 250ms silences: ABB\n",
    "    outwav = wavA + wavSIL250 + wavB + wavSIL250 + wavB\n",
    "    # Write to file\n",
    "    sentencename = './TestSentences/ABB/'+dumA+dumB+dumB+'.wav'\n",
    "    outwav.export(sentencename, format=\"wav\")\n",
    "\n",
    "    # Combine all wavs into one including 250ms silences: ABA\n",
    "    outwav = wavA + wavSIL250 + wavB + wavSIL250 + wavA\n",
    "    # Write to file\n",
    "    sentencename = './TestSentences/ABA/'+dumA+dumB+dumA+'.wav'\n",
    "    outwav.export(sentencename, format=\"wav\")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make example ABB, ABA trainining stimulus example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First ABB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) # Make these replicable\n",
    "ABBexample_wavfiles = np.array(glob.glob('./TrainingSentences/ABB/*.wav')) # Get list of files\n",
    "ABBexample_wavfiles = np.random.permutation(ABBexample_wavfiles)\n",
    "\n",
    "# Load the 1000ms silence file (silence between sentences)\n",
    "wavSIL250 = AudioSegment.from_wav('./SILfiles/SIL250ms.wav')\n",
    "wavSIL1000 = AudioSegment.from_wav('./SILfiles/SIL1000ms.wav')\n",
    "\n",
    "# Initialize with a short silence\n",
    "outwav = wavSIL250\n",
    "# Iterate over remaining files\n",
    "for wavfname in ABBexample_wavfiles:\n",
    "    dumwav = AudioSegment.from_wav(wavfname)\n",
    "    # Add in\n",
    "    outwav += dumwav + wavSIL1000\n",
    "# Add in final silence\n",
    "outwav += wavSIL250\n",
    "\n",
    "# Write out\n",
    "outwav.export('ABBexample.wav', format=\"wav\")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then ABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) # Make these replicable\n",
    "ABAexample_wavfiles = np.array(glob.glob('./TrainingSentences/ABA/*.wav')) # Get list of files\n",
    "ABAexample_wavfiles = np.random.permutation(example_wavfiles)\n",
    "\n",
    "# Load the 1000ms silence file (silence between sentences)\n",
    "wavSIL250 = AudioSegment.from_wav('./SILfiles/SIL250ms.wav')\n",
    "wavSIL1000 = AudioSegment.from_wav('./SILfiles/SIL1000ms.wav')\n",
    "\n",
    "# Initialize with a short silence\n",
    "outwav = wavSIL250\n",
    "# Iterate over remaining files\n",
    "for wavfname in ABAexample_wavfiles:\n",
    "    dumwav = AudioSegment.from_wav(wavfname)\n",
    "    # Add in\n",
    "    outwav += dumwav + wavSIL1000\n",
    "# Add in final silence\n",
    "outwav += wavSIL250\n",
    "\n",
    "# Write out\n",
    "outwav.export('ABAexample.wav', format=\"wav\")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
